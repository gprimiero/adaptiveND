\documentclass[]{article}

\usepackage[utf8]{inputenc} % set input encoding (not needed with XeLaTeX)
\usepackage{syntax}
\usepackage{amsfonts}
\usepackage{amssymb} 
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{mathpartir}
\usepackage{bussproofs}
\usepackage{wasysym}

\newtheorem{definition}{Definition}
\newtheorem{theorem}{Theorem}

\newcommand{\TurnADND}[2]
    { {#1}\vdash_{\textbf{\sf AdaptiveND}}  {#2}}

\newcommand{\Turn}[2]
    { {#1}\vdash_{\textbf{\sf s}}  {#2}}
\newcommand{\TurnNext}[2]
    { {#1}\vdash_{\textbf{\sf s+1}}  {#2}}
\newcommand{\TurnNextn}[2]
        { {#1}\vdash_{\textbf{\sf s+n}}  {#2}}
\newcommand{\TurnNextnn}[2]
        { {#1}\vdash_{\textbf{\sf s+n+1}}  {#2}}
\newcommand{\TurnNextNext}[2]
    { {#1}\vdash_{\textbf{\sf s+2}}  {#2}}

\newcommand{\TurnNextNextNext}[2]
    { {#1}\vdash_{\textbf{\sf s+3}}  {#2}}

\newcommand{\TurnPrime}[2]
    { {#1}\vdash_{\textbf{\sf s'}}  {#2}}

\newcommand{\TurnPrimePrime}[2]
    { {#1}\vdash_{\textbf{\sf s''}}  {#2}}


\newcommand{\TurnOne}[2]
    { {#1}\vdash_{\textbf{\sf 1}}  {#2}}
\newcommand{\TurnMarked}[2]
    { {#1}\vdash_{\textbf{\sf s\XBox}}  {#2}}

\newcommand{\TurnMarkedREL}[2]
    { {#1}\vdash_{\textbf{\sf s\XBox R}}  {#2}}
\newcommand{\TurnMarkedMA}[2]
    { {#1}\vdash_{\textbf{\sf s\XBox MA}}  {#2}}
\newcommand{\TurnChecked}[2]
    { {#1}\vdash_{\textbf{\sf \checked}}  {#2}}
\newcommand{\TurnMarkedNext}[2]
    { {#1}\vdash_{\textbf{\sf s+1\XBox}}  {#2}}
\newcommand{\TurnMarkedprime}[2]
    { {#1}\vdash_{\textbf{\sf s'\XBox}}  {#2}}


\newcommand{\TurnMaxPlusOne}[2]
        { {#1}\vdash_{\textbf{\sf max(s,s')+1}}  {#2}}


\newcommand{\TurnMarkedNextREL}[2]
    { {#1}\vdash_{\textbf{\sf s+1\XBox R}}  {#2}}
\newcommand{\TurnMarkedNextNextREL}[2]
    { {#1}\vdash_{\textbf{\sf s+n+1\XBox R}}  {#2}}
\newcommand{\TurnMaxPlusOneREL}[2]
    { {#1}\vdash_{\textbf{\sf max(s,s')+1\XBox R}}  {#2}}

\newcommand{\TurnMarkedNextMA}[2]
    { {#1}\vdash_{\textbf{\sf s+1\XBox MA}}  {#2}}
\newcommand{\TurnMarkedNextNextMA}[2]
    { {#1}\vdash_{\textbf{\sf s+n+1\XBox MA}}  {#2}}


%\newcommand{\TurnOne}[2]
%   { {#1}\vdash_{\textbf{\sf 1}}  {#2}}
\newcommand{\TurnTwo}[2]
    { {#1}\vdash_{\textbf{\sf 2}}  {#2}}
\newcommand{\TurnThree}[2]
    { {#1}\vdash_{\textbf{\sf 3}}  {#2}}
\newcommand{\TurnFour}[2]
    { {#1}\vdash_{\textbf{\sf 4}}  {#2}}
\newcommand{\TurnFive}[2]
    { {#1}\vdash_{\textbf{\sf 5}}  {#2}}
\newcommand{\TurnSix}[2]
    { {#1}\vdash_{\textbf{\sf 6}}  {#2}}

\newcommand{\TurnSeven}[2]
    { {#1}\vdash_{\textbf{\sf 7}}  {#2}}

\newcommand{\TurnMarkedSevenREL}[2]
    { {#1}\vdash_{\textbf{\sf 7\XBox R}}  {#2}}

\newcommand{\TurnMarkedEightREL}[2]
    { {#1}\vdash_{\textbf{\sf 8\XBox R}}  {#2}}


\newcommand{\TurnEight}[2]
    { {#1}\vdash_{\textbf{\sf 8}}  {#2}}


\newcommand{\TurnMarkedFiveMA}[2]
    { {#1}\vdash_{\textbf{\sf 5\XBox MA}}  {#2}}
\newcommand{\TurnMarkedEightMA}[2]
    { {#1}\vdash_{\textbf{\sf 8\XBox MA}}  {#2}}
    
\newcommand{\TurnNine}[2]
    { {#1}\vdash_{\textbf{\sf 9}}  {#2}}


\newcommand{\TurnTen}[2]
    { {#1}\vdash_{\textbf{\sf 10}}  {#2}}
    
\newcommand{\TurnEleven}[2]
        { {#1}\vdash_{\textbf{\sf 11}}  {#2}}
    

\newcommand{\TurnMarkedElevenREL}[2]
    { {#1}\vdash_{\textbf{\sf 11\XBox R}}  {#2}}


\newcommand{\TurnMarkedTwelveREL}[2]
    { {#1}\vdash_{\textbf{\sf 12\XBox R}}  {#2}}


\newcommand{\TurnThirteen}[2]
        { {#1}\vdash_{\textbf{\sf 13}}  {#2}}

\newcommand{\TurnFourteen}[2]
        { {#1}\vdash_{\textbf{\sf 14}}  {#2}}

\newcommand{\TurnFifteen}[2]
        { {#1}\vdash_{\textbf{\sf 15}}  {#2}}


\newcommand{\TurnSixteen}[2]
        { {#1}\vdash_{\textbf{\sf 16}}  {#2}}

\newcommand{\TurnSeventeen}[2]
        { {#1}\vdash_{\textbf{\sf 17}}  {#2}}


\newcommand{\TurnEighteen}[2]
        { {#1}\vdash_{\textbf{\sf 18}}  {#2}}

\newcommand{\TurnNineteen}[2]
        { {#1}\vdash_{\textbf{\sf 19}}  {#2}}


%\newcommand{\TurnT}[2]
%   { \Delta_0;{#1}\vdash  {#2}}
%\newcommand{\TurnTT}[2]
%   { \Delta_0;{#1}\vdash_{\sf JC_1}  {#2}}
%\newcommand{\Turnj}[1]
%   { \Delta_0\vdash_{\sf J_0}  {#1}}
%\newcommand{\Turnjc}[3]
%    { {#1};{#2}\vdash_{\textbf{\sf JC}}  {#3}}


%opening
\title{Annotated Natural Deduction for Adaptive Reasoning}
\author{Giuseppe Primiero\\
Department of Computer Science\\
Middlesex University London\\
 \and Patrick Allo\\
 Oxford Internet Institute\\
 University of Oxford}

\begin{document}

\maketitle

\begin{abstract}
We present a multi-conclusion natural deduction calculus based on minimal logic extended with a set of rules characterizing the dynamic reasoning typical of adaptive logics.
\end{abstract}

\section{Intro}

In this paper we outline a multiple-conclusion natural deduction calculus in which the dynamics of standard (Fitch-style) dynamic proofs of Adaptive Logics \cite{batens07} can be reconstructed. Adaptive logics are a family of logics that can be used to formalise a wide range of defeasible reasoning forms. The consequence-relations of adaptive logics rely on the standard idea of interpreting premises as normally as possible through the selection of models of its premises, and it is only at the level of its proof-theory that it's distinctive approach comes to the fore. Adaptive logics, namely, reconstruct defeasible reasoning patterns as dynamic proofs; proofs in which earlier steps may be retracted at a later stage when the assumptions they were based on no longer hold.

The specific system we describe here is for an inconsistency adaptive logic; a logic that captures the reasoning one obtains when one reasons paraconsistently to avoid triviality in the face of inconsistency, but that at the same time tries to make up for the deductive weakness of paraconsistent reasoning by interpreting the premises as consistently as possible. This choice brings us closer to the original motivations for the development of adaptive logic, but also allows us to engage with current philosophical debates and with certain aspects of Graham's work.

The dynamics of retracting earlier lines in a proof can be captured in a rather natural way in a linear proof-format, including standard axiomatic and Fitch-style natural deduction proofs, but is much less straightforward in a tree-like proof-format. Consider, for instance, the following retraction of what happens to be an instance of the application of \emph{Ex Contradictione Quodlibet}:

\begin{figure}[h!]
\centering
    \begin{tabular}{cllcl}
        (1) & $p$ & Prem & $\emptyset$\\
        (2) & $p \vee q$ & Add & $\emptyset$\\
        (3) & $\neg p$ & Prem & $\emptyset$\\
        (4) & $q$ & DS & $\{p\}$ & \checkmark$^5$\\
        (5) & $p \wedge \neg q$ & Adj & $\emptyset$
    \end{tabular}
\end{figure}
\noindent Here, at line (4) disjunctive syllogism is applied on the condition that $p$ behaves normally, i.e.\ that the contradiction $p \wedge \neg p$ hasn't been derived. When this contradiction is effectively derived at line (5), the line (4) is marked and is from then on no longer assumed to be part of the proof. This type of reasoning is the common core of how the idea of provisional applications of classical inference-rules can be applied to paraconsistent logics that reject the disjunctive syllogism, but in which the restricted form $\phi \vee \psi, \neg \phi / \psi \vee (\phi \wedge \neg \phi)$ is retained.

Contrast this, now, with the following attempt to reconstruct a similar reasoning-process in a Prawitz-style proof-tree:
\begin{prooftree}
    \AxiomC{$\Gamma \vdash p$}
    \RightLabel{$\vee$I}
    \UnaryInfC{$\Gamma \vdash p \vee q$}
    \AxiomC{$\Gamma \vdash \neg p$}
    \AxiomC{$\Gamma \not\vdash p \wedge \neg p$}
    \LeftLabel{DS$^*$}
    \TrinaryInfC{$\Gamma \vdash q$}  
    \AxiomC{$\Gamma \vdash p$}
    \AxiomC{$\Gamma \vdash \neg p$}
    \RightLabel{$\wedge$I}
    \BinaryInfC{$\Gamma \vdash p \wedge \neg p$}
    \BinaryInfC{?}
\end{prooftree}
When in the right-hand branch of the proof an explicit contradiction is derived, the assumption that no such contradiction is derived (which is stated explicitly in the left-hand branch) no longer holds. In this format, however, the order used to construct the proof cannot be read off the proof itself (an issue that could easily be fixed), but more importantly, it isn't even clear what it might mean to retract the line where $q$ is derived since the result of removing that line from the proof it itself no longer a well-formed proof.

The proof-format we propose solves this problem by adding indices to judgements to keep track of stages in the construction of a proof, and by exploiting the fact that since every assumption or premise that is used in a proof-step should explicitly be written down in the place it is used, judgements that are `marked' at a certain stage do not have to be removed because there is simply no need to prevent their implicit re-use. Instead, it is the derivation of the same judgement at a later stage that is (or may be) blocked because the original assumption that led to its initial derivation probably no longer holds.

Additionally, the system makes the connection between unconditional derivations of certain disjunctions in the paraconsistent logic and the conditional deductions of one of their disjuncts in the adaptive logic explicit by adopting multiple-conclusion judgements. This formal feature has the additional advantage that it allows us to re-assess certain current debates regarding the question of how one should best approach the question of classical recapture in paraconsistent logics.

HERE 

When one adopts a logic that is strictly weaker than classical logic, the question of how one should account for epistemically useful classical inference-forms that are invalidated by one's preferred logic almost immediately arises. In the case of paraconsistent logic this question is often deemed quite urgent, as the practical and epistemic usefulness of the inference-forms that are lost, like the disjunctive syllogism, are almost undisputed. This is the problem of \emph{classical recapture}. Inconsistency-adaptive logics present one possible answer to this challenge under the form of defeasible inference-forms that allow one to use classical inference-steps on the condition that certain assumptions are not violated. The class of adaptive logics that have been formulated since the earliest formulation of this paradigm as a response to the problem of classical recapture generalise this idea, and provide a general framework in which many types of defeasible inference-forms can be rigourously formalised.

In several papers Graham Priest has explicitly endorsed this type of approach to the classical recapture problem of the paraconsistent logic \textbf{LP}, and has defended his own preferred formalisation and motivation for what he calls \emph{Minimally Inconsistent LP}. When compared to the systems developed in the adaptive logic tradition, this system stands out because it is based on a strong paraconsistent logic that nevertheless lacks a detachable implication (which makes the problem of classical recapture even more stringent), but also because it is put forward as a potential universal inference engine that can be applied in all contexts. At the level of its formal characterisation, minimally inconsistent LP differs from its closest neighbour ACLuNs$^m$ 



% We present a multi-conclusion natural deduction calculus that mimics the dynamic reasoning at work in adaptive logics (\cite{batens07}). This is the first attempt to reconstruct the dynamics typical of adaptive logics in a natural deduction setting. The resulting system does not correspond to the usual structure known as the Standard Format for Adaptive Logics: this means that, though we \textit{do not} introduce an adaptive logic proper, we can talk of a natural deduction system for \textit{adaptive reasoning}. We characterize such a way of reasoning as having properties that identify adaptive dynamics.  To do so, the standard proof-theoretical procedure of a natural deduction system is enhanced with:

% \begin{enumerate}
% \item a rule-based ability of introducing abnormal formulas of the form $A\wedge \neg A$;\footnote{In the current format we focus on inconsistency-adaptive logics, though the generalization to the natural deduction for other adaptive formats seems possible.} the appearance of such formulas on the right-hand side of our derivability sign justifies the claim that our system is extended to a multi-conclusion setting;

% \item a rule-based ability of deriving formulas under conditions that some such abnormal formula is not true;

% \item the procedural ability of rejecting derivation steps previously obtained by way of marking in view of effectively derived abnormal formulas.
% \end{enumerate}

% These are all properties inspired by the adaptive logics approach. In view of the last property, we need moreover to annotate the derivability relation with a stage counting mechanism to keep track of the steps performed in the derivation tree (thus counting also premises rather than only rules).

% %These are all properties inspired by the adaptive logics approach. This means that, though we \textit{do not} introduce an adaptive logic proper, we can talk of a natural-deduction system for \textit{adaptive reasoning}. In fact, 
% Our system is not even close to a standard format for AL. We express the standard triple $\{LLL,\Omega,STRATEGY\}$ in a system where the Lower Limit Logic is extended to include rules both for expressing the abnormal formulas in $\Omega$ and to interpret the selection Strategy. In other words, this rule-based approach allows to merge the rules and axioms of a typical $LLL$ and the rules of the $AL$ based on abnormal formulas into a single system of rules. 

%\subsection*{Other Works}
%xxx


\section{{\sf minimalND}}

We start by defining the type universe for the $\{\neg, \rightarrow, \wedge, \vee\}$ fragment of intuitionistic propositional logic corresponding to minimal logic. We call this logic {\sf minimalND} and use it as the equivalent of a Lower Limit Logic: we do not explicitly formulate a rule to abort derivations once a proposition of type $\bot$ is derived, as it would be standard in an intuitionistic setting. Instead, we allow a contradiction elimination that corresponds to \textit{ex falso quodlibet}. It will be the role of the adaptive machinery introduced in the next sections to establish how to remove such contradictions.

We start defining the syntax of our language:

\begin{definition}[{\sf minimalND}]

 Our starting language for {\sf minimalND} is defined by the following grammar:
 
\begin{displaymath}
\begin{array}{l}
{\sf Type}:={\sf Prop}\\
{\sf Prop}:= A | \bot | \neg \phi \mid \phi_{1} \rightarrow \phi_{2} | \phi_{1} \wedge \phi_{2} | \phi_{1} \vee \phi_{2}\\
\Gamma := \{\phi_{1}, \dots, \phi_{n}\}\\
\Delta := \{\phi_{1}, \dots, \phi_{n}\}

\end{array}
\end{displaymath}
\end{definition}

%
The type universe of reference is the set of propostions {\sf Prop}, construed by atomic formulas closed under negation, implication, conjunction, disjunction and allowing $\bot$ to express contradictions. Formula formation rules are given in Figure \ref{fig:formulaconstructions}. 

\begin{figure}[h!]
\begin{mathpar}
\infer*[right=Atom] { } {A \in {\sf Prop}}
\and
\infer*[right=$\bot$] { } {\bot \in {\sf Prop}}
\and
\infer*[right=$\neg$] {\phi \in {\sf Prop} } {\neg \phi \in {\sf Prop}}
\and
\infer*[right=$\rightarrow$] {{\phi_1 \in {\sf Prop }}\\ {\phi_2 \in {\sf Prop}}} {\phi_1\rightarrow\phi_2\in {\sf Prop}}
\and
\infer*[right=$\wedge$] {{\phi_1 \in {\sf Prop }}\\ {\phi_2 \in {\sf Prop}}} {\phi_1\wedge\phi_2\in {\sf Prop}}
\and
\infer*[right=$\vee$] {{\phi_1 \in {\sf Prop }}\\ {\phi_2 \in {\sf Prop}}} {\phi_1\vee\phi_2\in {\sf Prop}}
\end{mathpar}
\caption{Formula Formation Rules}\label{fig:formulaconstructions}
\end{figure}



\begin{definition}[Judgements]
A {\sf minimalND}-judgement is of the form $\Gamma;\cdot \vdash_{\sf s} \Delta$, where: $\Gamma$ is the usual set of assumptions, $\Delta$ is a set of formulas of the language and {\sf s} is a positive integer.
\end{definition}
The set $\Gamma$ on the left-hand side of the derivability sign is to be read conjunctively. Similarly for the semi-colon symbol, which is introduced here but is only used in Section \ref{sec:adaptive} to separate standard assumptions in $\Gamma$ from conditions (in the adaptive sense). The set $\Delta$ and the possible comma on the right-hand side of the derivability sign are both to be read disjunctively. This characterize our calculus as multi-conclusion. Context formation rules, for both left and right-hand side set of formulas are given in Figure \ref{fig:contextrules}. {\sf Nil} establishes the base case of a valid empty context, we use {\sf wf} as an abbreviation for `well-formed'; $\Gamma${\sf -Formation} allows extension of contexts by propositions; {\sf Prem} establishes derivability of formulas contained in context (and it defines the equivalent of the adaptive Premise rule); finally, $\Delta${\sf -Formation} allows \textit{disjunctive} extension of derived sets of formulas by well-typed ones.


\begin{figure}[h!]
\begin{mathpar}
\infer*[right=Nil] { } {\cdot\Turn {} {\sf wf}}
\and
\infer*[right=$\Gamma$-formation] {{\Turn {\Gamma; \cdot} {\sf wf} } \\ {\phi \in {\sf Prop}}} {\TurnNext {\Gamma , \phi; \cdot} {\sf wf}}
\end{mathpar}


\begin{mathpar}
\infer*[right=Prem] {{\Turn {\Gamma; \cdot} {\sf wf}}\\ {\phi \in \Gamma}}{\TurnNext {\Gamma; \cdot} {\phi}}
\and
\infer*[right=$\Delta$-formation] {{\Turn {\Gamma; \cdot} {\Delta \cup \{\phi\}}}} {\TurnNext {\Gamma; \cdot} {\Delta, \phi}}

\end{mathpar}
\caption{Context Formation Rules}\label{fig:contextrules}
\end{figure}

 The derivability sign is enhanced with a signature {\sf s} that corresponds to a counter of the ordered derivation steps executed to obtain the corresponding ND-formula in a tree. This annotation only comes to use in the next extension of the calculus in Section \ref{sec:adaptive}. 

The semantics of connectives is given in the standard proof-theoretical way by way of Introduction and Elimination Rules in Figure \ref{fig:connectives}. Introduction of $\rightarrow$ corresponds to the Deduction Theorem, while its elimination formalises Modus Ponens. Rules for $\wedge$ are standard; notice that $\vee$-Elimination amounts to formation of a multi-conclusion judgement. $\neg$-Elimination is \textit{ex falso}, while its Introduction is modelled by the translation of positive formulas on the left-hand side of the derivability sign, to their negative counterpart on the right-hand side.
%
%
\begin{figure}[h!]
\begin{mathpar}
\infer*[right=$\rightarrow$I] {\Turn {\Gamma, \phi_1; \cdot} {\phi_2}} {\TurnNext {\Gamma; \cdot} {\phi_1\rightarrow \phi_2}}
\and
\infer*[right=$\rightarrow$E] {\Turn {\Gamma; \cdot} {\phi_1\rightarrow\phi_2}\\{\TurnPrime {\Gamma';\cdot} {\phi_1}}} {\TurnMaxPlusOne {\Gamma; \Gamma'} {  \phi_2}}
\end{mathpar}

\begin{mathpar}
\infer*[right=$\wedge$I] {\Turn {\Gamma;\cdot} {\phi_1}\\{\TurnPrime {\Gamma'; \cdot} {\phi_2}}} {\TurnMaxPlusOne {\Gamma, \Gamma';\cdot} {\phi_1\wedge \phi_2}}
\and
\infer*[right=$\wedge$E] 
{\Turn {\Gamma;\cdot} {\phi_1\wedge\phi_2}} {\TurnNext {\Gamma;\cdot} {  \phi_{i \in \{1,2\}}}}
\end{mathpar}


\begin{mathpar}
\infer*[right=$\vee$I] {\Turn {\Gamma;\cdot} {\phi_1}} {\TurnNext {\Gamma;\cdot} {\phi_1\vee \phi_2}}
\and
\infer*[right=$\vee$I] {\Turn {\Gamma;\cdot} {\phi_2}} {\TurnNext {\Gamma;\cdot} {\phi_1\vee \phi_2}}
\and
\infer*[right=$\vee$E] 
{\Turn {\Gamma;\cdot} {\phi_1\vee\phi_2}}{\TurnNext {\Gamma;\cdot} {  \phi_{1},\phi_{2}}}
\end{mathpar}


\begin{mathpar}
\infer*[right=$\bot$E] {\Turn {\Gamma; \cdot}{\bot} }{\Turn {\Gamma;\cdot} {\phi}}
%\end{mathpar}
\and
%\begin{mathpar}
\infer*[right=$\neg$I] {\Turn {\Gamma; \phi}{\psi}}{\TurnNext {\Gamma; \cdot}{\psi, \neg \phi}}
\end{mathpar}

\caption{Rules for I/E of connectives}\label{fig:connectives}
\end{figure}



Finally, we introduce a set of rules to enforce structural properties in Figure \ref{fig:structural}.  {\sf Wleft} is a Weakening on the left-hand side of the judgement: it allows the monotonic extension of assumptions preserving already derivable formulas. Notice that this rule can only work with a strictly empty set of formulas $; \cdot$ following $\Gamma$: we shall introduce in the next section this as the set of \textit{adaptive conditions}. The reason for this requirement in {\sf Wleft} is that the set of adaptive conditions strictly depends on the set of assumptions $\Gamma$, hence a Weakening of the latter can imply a different formulation of the former. We do not need to formulate a {\sf Wright} rule for weakening of the set $\Delta$ of derivable formulas, as this can be obtained by a detour of $\vee$-Introduction and Elimination. {\sf Cleft} for Contraction on the left allows elimination of repeted assumptions and {\sf Eleft} is valid just by set construction, as there is no order. {\sf Cright} and {\sf Eright} do a similar job on the right-hand side of the judgement. Finally, {\sf Cut} (also known as {\sf Substitution} in some Natural Deduction Caluli) guarantees that derivations can be pasted together, and it in generals requires that there are no clashes of free variables in $\Gamma, \Gamma'$.




\begin{figure}[h!]
\begin{mathpar}
\infer*[right=Wleft] {\Turn {\Gamma; \cdot} {\phi_{1}} } {\TurnNext {\Gamma, \phi_{2}; \cdot} {\phi_{1}}}
\and
\infer*[right=Cleft] {\Turn {\Gamma, \phi_{1}, \phi_{1}; \cdot} {\phi_{2}} } {\TurnNext {\Gamma, \phi_{1}; \cdot} {\phi_{2}}}
\and
\infer*[right=Eleft] {\Turn {\Gamma, \phi_{1}, \phi_{2}; \cdot} {\phi_{3}} } {\TurnNext {\Gamma, \phi_{2}, \phi_{1}; \cdot} {\phi_{3}}}
\end{mathpar}
\begin{mathpar}

\infer*[right=Cut] {\Turn {\Gamma; \cdot} {\phi_{1}} \\ {\TurnPrime {\Gamma', \phi_{1}; \cdot} {\phi_{2}}}} {\TurnMaxPlusOne {\Gamma; \Gamma'; \cdot} {\phi_{2}}}
\end{mathpar}
\begin{mathpar}

\infer*[right=Cright] {\Turn {\Gamma; \cdot} {\phi, \phi}} {\TurnNext {\Gamma; \cdot} {\phi} }
\and
\infer*[right=Eright] {\Turn {\Gamma; \cdot} {\phi_{1}, \phi_{2}} } {\TurnNext {\Gamma; \cdot} {\phi_{2}, \phi_{1}}}
\end{mathpar}
\caption{Structural Rules}\label{fig:structural}
\end{figure}

% % % %NOT DONE THIS

%
%We should also remember that this Minimal Logic fragment verify
%
%\begin{figure}[h]
%\begin{mathpar}
%\infer*[right=] {\Turn {\Gamma; \cdot} {\phi\rightarrow\psi}} {\TurnNext {\Gamma; \cdot} {\neg \phi,  \psi}}
%\end{mathpar}
%\end{figure}
%
%but it does not verify
%
%\begin{figure}[h]
%\begin{mathpar}
%\infer*[right=] {\Turn {\Gamma; \cdot} {\neg \phi\rightarrow\psi}} {\TurnNext {\Gamma; \cdot} {\phi,  \psi}}
%\end{mathpar}
%\end{figure}
%
%hence is not fully CLuN equivalent.
%]

\section{{\sf AdaptiveND}}\label{sec:adaptive}


We now extend {\sf minimalND} to characterize a new logic called {\sf AdaptiveND} to allow for inconsistency adaptive reasoning. To this aim one needs: 
% 
\begin{enumerate}
\item the explicit formulation of an $\Omega$ set of propositions of type $\bot$;
\item the formulation of judgements including an \textit{adaptive condition};
\item the formulation of a rule that allows to derive new formulas independent from such an adaptive condition;
\item the formulation of a rule that allows to derive new formulas dependently from such an adaptive condition.
\end{enumerate}
%
We offer accordingly new definitions for the syntax of this new logic and the related form of judgement.

\begin{definition}[{\sf AdaptiveND}]
The language of {\sf AdaptiveND} is as follows:


\begin{displaymath}
\begin{array}{l}
{\sf Type}:={\sf Prop}\\
{\sf Prop}:= A | \bot | \neg \phi | \phi_{1} \rightarrow \phi_{2} | \phi_{1} \wedge \phi_{2} | \phi_{1} \vee \phi_{2}\\
% | \phi_{1} \vee_{\sf CL} \phi_{2}\\
\Gamma := \{\phi_{1}, \dots, \phi_{n}\}\\
\Delta := \{\phi_{1}, \dots, \phi_{n}\}\\
\Omega := \{\phi \wedge \neg \phi\mid \phi\in Prop\}\\
%Dab(\Delta) := \phi_{1} \vee_{\sf CL} \phi_{2}\mid \phi_{1},\phi_{2}\in \Omega
\end{array}
\end{displaymath}
\end{definition}




\begin{definition}[Judgements]
An {\sf AdaptiveND}-judgement is of the form $\Gamma; \phi^{-}\vdash_{s} \Delta$, where: 

\begin{enumerate}
\item the left-hand side of $\vdash_{\sf s}$ has $\Gamma$ as in {\sf minimalND};
\item the semicolon sign on the left-hand side of $\vdash_{\sf s}$ is conjunctive;
\item $\phi$ refers to a formula in $\Omega$, i.e. with a specific inconsistent logical form; below we introduce an appropriate $\Omega$-formation rule;\footnote{As mentioned above, the current setting of {\sf AdaptiveND} is specified for an inconsistency-adaptive logic.}
\item the last place of the left-hand side context is always reserved to negated formulas of the $\Omega$ form; we shall use $\phi^{-}$ to refer to the negation of $\phi$, for all $\phi\in \Omega$;
\item the right-hand side is in disjunctive form.
\end{enumerate}
\end{definition}
%
When $\Omega$ is empty on the left-hand side of $\vdash$, we shall write $\Gamma;\cdot\vdash$, thus reducing to the form of a {\sf minimalND}-formula. 
%When $\Omega$ is empty on the right-hand side of $\vdash$, we shall write simply $\vdash A$. In view of point $4.$ above, this natural deduction calculus can also be characterized as a multiple conclusion calculus.\footnote{There is a certain similarity between $\vdash ;\Omega$ and the notion of \textit{denied formulas} in a state from \cite{restall2005}: the standard way to read the right hand side of an {\sf AdaptiveND}-formula is in fact that of an exclusive ``or".} 
Moreover, in {\sf AdaptiveND}, the annotation on the proof stage {\sf s} is optionally followed by one of the following two marks: $\XBox$ to mark that at the current stage some previously derived formula is retracted; $\checked$ to mark that at the current stage some previously derived formulas is now stable, i.e. will no longer marked by $\XBox$. These symbols will be formally introduced in Sections \ref{sec:marking} and \ref{sec:meta} respectively. 
%We shall also use below the abbreviation $\neg\phi:=\phi\rightarrow\bot$. 

%A feature of {\sf AdaptiveND} that we will use below is that it requires to have \textit{classical disjunctions of formulas generated under the $\Omega$-rule}. To be more precise, whenever we derive more than a formula in the set $\Omega$, we might want to establish which of those is unavoidable, and thus extend $\Gamma$ with a set of disjunctions of $\omega$'s which is classical (as we cannot infer it from any already verified $\omega$). This means that {\sf AdaptiveND} needs a new formation rule for $\vee_{\sf CL}$, which is in fact restricted to $\phi$'s that are in $\Omega$. We shall also give a formation rule for $\Omega$ and one for $\Gamma; \Omega^{-}$. Furthermore, two additional rules are introduced for deriving formulas, simply or on conditions. 

%The mechanism enforced by the marking definitions (either for retracting or for stabilizing a derived content) makes a proof a sequence of derivation steps. The dynamic nature of this form of reasoning is implemented in our ND calculus by allowing extensions by derivation steps appended at the end of the current proof-tree.\footnote{That is, we will avoid the more complex approach that allows for line insertions in a given derivation.} For obtaining the stable notion of final derivability, it will be useful to allow \textit{infinite} extensions of a proof-tree.

%\subsection{Rules of {\sf AdaptiveND}}

We now introduce the rules for {\sf AdaptiveND}. In Figure \ref{fig:omega}, we illustrate the formation and use of formulas $\phi \in \Omega$. By $\Omega${\sf-Formation }, given a proposition $\phi$ (possibly non-atomic), a contradiction with $\neg \phi$ is a formula of the $\Omega$ type; following the Adaptive tradition $\phi$ can also be called an \textit{abnormality} or an \textit{abnormal fomrula}. By {\sf Adaptive Condition Formation}, given a valid context $\Gamma$ and a formula $\phi$ of the $\Omega$ type, a context $\Gamma$ followed by the adaptive Condition stating that $\phi$ \textit{is false}, is  awell-formed context. This corresponds to the use of conditions as additional elements of proof line in the standard Adaptive proof theort (Fitch-style).

\begin{figure}[h!]
\begin{mathpar}
\infer*[right=$\Omega$-formation] {{\phi \in {\sf Prop}}}{(\phi \wedge \neg \phi) \in \Omega}
%
% {{\Turn {\Gamma;\cdot} {\phi}}\\ {\TurnNext {\Gamma, \phi; \cdot} {\neg\phi}}} 
%{\TurnNextNext {\Gamma; \cdot} {{\sf \Omega}}} 
\and
\infer*[right=Adaptive Condition-formation] {{\Turn {\Gamma;\cdot} {\sf wf} } \\ {\phi \in {\sf \Omega}}} {\TurnNext {\Gamma ; \phi^{-}} {\sf wf}}
\end{mathpar}
\caption{$\Omega$ Formation rules}\label{fig:omega}
\end{figure}


Next, the calculus is extended by introducing two rules, see Figure \ref{fig:adaptiverules}. $RU$ is called the unconditional rule: it says that if a formula $\phi_{1}$ is derivable in {\sf AdaptiveND}, and another formula $\phi_{2}$ is derivable from $\phi_{1}$ without additional assumptions or adaptive conditions, then $\phi_{2}$ is derivable from $\phi_{1}$ and the context $\Gamma;\phi^{-}\vdash$ in which the latter holds.  $RC$ is  called the conditional rule: it says that if a disjunction $\psi,\phi$ is derivable from $\Gamma$, with $\phi$ an abnormal formula, then $\psi$ can also be derived alone under $\Gamma$ and the Adaptive Condition that $\phi$ be false.

\begin{figure}[h!]
\begin{mathpar}
\infer*[right=RU] {\Turn {\Gamma; \phi^{-}} {\phi_{1}}\\ {\TurnNext {\phi_{1};\cdot} {\phi_{2}}}}
{\TurnNextNext {\Gamma, \phi_{1}; \phi^{-}} {\phi_{2}}}
\and
\infer*[right=RC] {\Turn {\Gamma;\cdot} {\psi,\phi}\\ {\phi \in \Omega}} {\TurnNext {\Gamma; \phi^{-}} {\psi}}
\end{mathpar}

\caption{Adaptive Rules}\label{fig:adaptiverules}
\end{figure}


 
The Adaptive strategy developed in the next Section has the aim of establishing which abnormal formulas can no longer be safely considered as conclusions of an {\sf Adaptive Condition Formation} Rule, thereby requiring a retraction of the formulas that are derivable from it. To this aim, it is essential to establish minimal disjunctions of such formulas, denoted by $\bigvee(\Delta^{min})$, with $\Delta\in \Omega$. The rule in Figure \ref{fig:mindab} establishes the construction of such minimal disjunctions. It says that given a derivable disjunctive formula of the $\Omega$ type at some stage {\sf s} of a derivation, that can be considered minimal at stage {\sf s'} if at no previous stage {\sf t} $<$ {\sf s'} a shorter one can be derived in the same context $\Gamma$.

\begin{figure}[h!]
\begin{mathpar}
\infer*[right=MinDab] {\Turn {\Gamma; \cdot} {\Delta}\\ {\Delta \subset \Omega} \\ {\mbox { with no }\Delta'\subseteq \Delta \in \Omega, \mbox{ s.t. } \Gamma; \cdot \vdash_{\sf t<s'} \Delta'}} {\TurnPrime {\Gamma; \cdot} {\Delta^{min}}}
\end{mathpar}
\caption{Minimal Abnormal Formulas Rule}\label{fig:mindab}
\end{figure}


The derivation of minimal disjunction of abnormalities is a process that occurs along with the development of the proof-tree. This means that the following procedure to mark formulas depend on the possible derivation of certain such formulas.


\subsection{A simple example}\label{sec:example}

We present here a simple derivation in {\sf AdaptiveND}, where $\Gamma=\{(\neg p \vee q),p,(p\rightarrow q)\}$:



\begin{mathpar}
\infer*[right=RC]{
\infer*[right=$\wedge$I] {
\infer*[right=$\vee$E]{ 
\infer*[right=PREM] {\phantom{xx}} {\TurnOne {\Gamma; \cdot}{(\neg p \vee q)}}}{\TurnTwo {\Gamma;\cdot}{\neg p, q}}\\ 
\infer*[right=PREM] {\phantom{xx}} {\TurnThree {\Gamma; \cdot}{p}}}{\TurnFour {\Gamma; \cdot}{(p\wedge \neg p), q}}\\
{(p \wedge \neg p)\in \Omega}}{\TurnFive {\Gamma;(p \wedge \neg p)^{-}}{q}}
\end{mathpar}
\bigskip
%%
%Notice that at stage $2$, $B$ can be derived under the $\Gamma\Omega^{-}$ formation rule, as $\Gamma$ contains $\neg B$. Next, $\neg B$ can be also derived under the premise rule. We obtain a conflict between derivations at stages $2$ and $6$. Next we want to establish how to retract one.

The derivation above up to stage $4$ is a obtained by {\sf MinimalND} rules. Stage $5$ derives a formula on condition of the abnormality $(p\wedge \neg p)$ being false.  This corresponds to changing a multiple conclusion judgement at stage $4$ into a single conclusion one at stage $5$ by turning one of the conclusions into an adaptive condition. This move is justified by the syntactical form of the abnormality declared by the \textsc{RC} rule.


 
\section{Rules for Marking}\label{sec:marking}

In standard Adaptive Logics, one introduces strategies to tell, given some judgement deriving a  Minimal Disjunction of Abnormalities, which one of the disjunct can be assumed to be false, i.e. for which one a {\sf RC} rule can be applied; and which one has to be accepted. Accordingly, formulas derived under the former can be considered valid, formulas previously derived by assuming the latter false have to be retracted. Adaptive Logics come with marking mechanisms that allow such retractions, according to different possible strategies. The most well-known strategies and their rationale are:\footnote{Some reference here?}

\begin{itemize}
\item \textit{Reliability}: once a $\bigvee(\Delta^{min})$ is derived at some stage {\sf s}, \textit{every} formula assuming at some stage {\sf s-i} a $\phi\in \bigvee(\Delta^{min})$ at $s$ to be false, needs to be retracted;

\item \textit{Minimal Abnormality}: once a $\bigvee(\Delta^{min})$ is derived at some stage {\sf s}, \textit{every} formula assuming at some stage {\sf s-i} a $\phi\in \bigvee(\Delta^{min})$ at $s$ to be false and such that $\phi$ is in a minimal set of $\Delta$, needs to be retracted.
\end{itemize}
%
In the first case, one considers all possible abnormal formulas to be invalid; in the second case, one tries to minimize the number of such unavoidable contradictions. In this section, we provide rules that extend {\sf AdaptiveND} in view of the Reliability strategy, providing a proof-theoretical equivalent of the standard marking condition. 
%s according to Reliability and Minimal Abnormality. 
We leave the definition of a proof-theoretical Minimal Abnormality strategy to a later stage.


\subsection{Marking Rule for Reliablity}

Reliability is the derivability strategy that takes the most cautious interpretation of abnormalities: any formula that in view of the premises might behave abnormally, because it occurs in a minimal disjunction of abnormalities, is deemed unreliable and should not be assumed to behave normally. This means in practice that at any proof stage where a formula $\psi$ is derived using some $\phi^{-}\in \Omega$ in context by an instance of the corresponding formation rule, is `marked'. Here marking means to reject the formula $\psi$, or invalidate it. In the following we shall introduce a new derivability rule that internalizes this process in {\sf AdaptiveND}.

%We shall first introduce a notion of union of all so-called unreliable formulas. To this aim, in the following we will refer to $\Sigma=\bigcup\{\Gamma,\Omega^{-}\}$, for some premises $\Gamma$ and some abnormal formulas $\Omega$ derivable from $\Gamma$:
%%
%%
%\begin{definition}[The set of unreliable formulas of $\Gamma$]
%$U_{{\sf s}}{(\Gamma)}$ is defined by the union of $\Delta\subseteq\Omega$, where $\Gamma\vdash\Delta_{1}, \dots, \Delta_{n}$ are respectively $Dab(\Delta)^{min}_{1}, \dots, Dab(\Delta)^{min}_{s}$.
%\end{definition}



We define a new derivability rule $\XBox$R  that depends on the formulation of the union set of all minimal $\bigvee(\Delta^{min})$  obtained by instances of the \textsc{MinDab} rule above. 

\begin{mathpar}
\infer*[right=$\XBox$R]{\Turn{\Gamma;\cdot}{\Delta^{min}}\\ \TurnPrime{\Gamma; \phi^{-}}{\psi} \\ {\phi \in \Delta^{min}}}
{\TurnMaxPlusOneREL{\Gamma}{\psi}}
\end{mathpar}


%\begin{mathpar}
%\infer*[right=$\XBox$R]{\Turn{\Sigma;\cdot}{\Delta^{min}}\\ \TurnPrime{\Sigma; \Psi^{-}}{\phi} \\ {\Psi \cap \Delta^{min}\neq \emptyset}}
%{\TurnMaxPlusOneREL{\Sigma}{\phi}}
%\end{mathpar}


The meaning of $\XBox \textsc{R}$ is the following: if at stage {\sf s} a minimal disjunction of abnormalities $\Delta^{min}$ is derived for $\Gamma$, and at a later stage {\sf s'} a formula $\psi$ is derived from the same premise set by assuming a component of $\Delta^{min}$ false by an {\sf Adaptive Condition Formation} rule, then at a next stage $\psi$ is marked as retracted.


\subsection{Extending the example}

Let us now extend the example from Section \ref{sec:example} with a new branch to illustrate the derivation step obtained by the Marking Rule $\XBox$R. Let us call $\mathbb{D}$ the derivation already shown, which had as a conclusion at stage {\sf 5} the derivation of $q$ in context $\Gamma$ and under the adaptive condition that $(p \wedge \neg p)$ is false. We extend it now as follows:

%\begin{mathpar}
%\infer*[right=some]{\infer*[right=UR]{\infer*[]{\infer*[vdots =1.5 em]{} {\TurnOne {\Gamma; \cdot} {\Delta_{1}}}}{\Turn {\Gamma; \cdot}{\Delta_{n}}}}{\TurnNextn{\Gamma,\Gamma';\cdot}}}{B;Dab(\Delta)^{min}_{i}}
%\end{mathpar}

\begin{mathpar}
\infer*[right=\XBox R]{
{
\infer*[]{
\mathbb{D}\qquad}{\TurnFive{\Gamma; (p \wedge \neg p)^{-}}{q}}}\\
\infer*[right=$\wedge$ I]
{
\infer*[right=$\rightarrow$ E]{{\TurnSix{\Gamma;\cdot}{p}}\\{\TurnSeven{\Gamma; \cdot}{p\rightarrow \neg p}}}
{\TurnEight {\Gamma; \cdot}{\neg p}}\\{\TurnNine {\Gamma; \cdot}{p}}}{\TurnTen {\Gamma;\cdot}{p\wedge\neg p}}}
{\TurnMarkedElevenREL {\Gamma;\cdot }{q}}
\end{mathpar}
\bigskip

In this derivation a new abnormality is derived at stage {\sf 10}, namely the same that is assumed to be false at stage {\sf 5}. Notice that it is essential that this abnormality be derived under an empty condition, i.e. under context $\Gamma;\cdot$, as explained above for the required strict condition on {\sf WLeft}. Moreover, a difference between the Fitch-style proofs standard for Adaptive Logics and the Natural Deduction derivation style becomes here evident. In the former, a marking rule implies the need to proceed backwards on the derivation, to mark all previous occurrences of the marked formula which can no longer be considered derived. In the latter, on the other hand, there is no need to remove formulas because the result obtained at stage $5$ cannot be reused in an extension of this proof.  Instead a new derivation step is performed (stage {\sf 11}), where the conclusion $q$ is marked. Moreover, if we were ever to get again $\Gamma; (p \wedge \neg p)^{-} \vdash_{\sf i} q$, that would be obtained by some new derivation $\mathbb{D}^{\prime}$ and therefore result as a conclusion at some stage ${\sf i>5}$.


%
%where $\Delta_{i}$ can be any of abnormal formulas derived at any line {\sf s}. Then we want to mark as invalid the last step of this derivation where $B$ is derived, if it relies on $\Omega^{-}$ containing at least one minimal abnormal formula. In the following we abbreviate assumptions sets $\Gamma, \Gamma'$ in a tree by $\Sigma$. Then we define a marking rule:
%The example above is then extended with two additional derivation steps:
%
%\begin{mathpar}
%
%\infer*[right=$\XBox$R]
%{
%\infer*[right=$\XBox$R]
%{
%\infer*[right=RC]{
%\infer*[right=$\vee_{CL}$] {
%\infer*[right=RU] {\infer*[right=$\Gamma\Omega^{-}$] {\infer*[right=PREM] {\phantom{xx}} {\TurnOne {\Gamma; \cdot}{B}}} {\TurnTwo {\Gamma; \{B\wedge \neg B\}^{-}}{B}}\\ \infer*[right=PREM] {\phantom{xx}} {\TurnThree {\Gamma; \cdot}{\neg B}}} {\TurnFour {\Gamma; \{B\wedge \neg B\}^{-}}{\{B\wedge \neg B\}}}
%}
%{\TurnFive {\Gamma;\cdot}{\{\neg B\wedge \neg\neg B\};{\{B\wedge \neg B\}}}
%}
%}
%{\TurnSix {\Gamma; (\{\neg B\wedge \neg\neg B\}^{min}_{5})^{-}}{\neg B}}
%}
%{\TurnMarkedSevenREL{\Gamma; \cdot}{\neg B}}
%%\\ {\{B\wedge \neg B\}\}\in U_{{\sf 2}}(\Gamma)}
%}
%{\TurnMarkedEightREL{\Gamma; (\{B\wedge \neg B\}^{min}_{2})^{-}}{B}}
%%
%%
%%{\TurnTwo {\Gamma; \{B\wedge \neg B\}^{-}}{B}}\\ \infer*[right=PREM] {}{\TurnThree {\Gamma; \cdot}{B}}
%%
%%
%%{
%%\infer*[right=RC] {\TurnFour {\Gamma; \cdot}{\{B\wedge \neg B\};\{\neg B\wedge \neg\neg B\}}} {\TurnFive {\Gamma; \{\neg B\wedge \neg\neg B\}}{\neg B}}}
%\end{mathpar}
%
%The marking step  $11$ tell us the original lines at which the minimal unreliable formulas in view of the premise set at a given step were obtained (resp. $5$ and $2$;  we have skipped an additional line repeating the derivability of $B$ before its marking).\footnote{This is a sensible difference with the marking mechanism in place for standard adaptive logics, where the marking itself happens at the line whose content is retracted and the formulation of the set of unreliable formulas remains entirely outside of the derivation. Notice that a shortcoming of the standard marking mechanism is that it does not provide indications on the stage at which the marking is executed.}

%\subsection{Marking Rule for Minimal Abnormality}
%
%
%Minimal abnormality is the marking strategy that reflects the following condition: a formula $\phi$ is retracted if at every stage {\sf s} at which it can be derived, it is so always on a non-empty condition of any of the minimal choice set of the set of abnormal formulas of its premises. Hence, we first introduce a set of minimal choice sets of abnormalities:
%
%\begin{definition}
%We call $\Phi_{{\sf s}}(\Gamma)$ the set of minimal choice sets of $\{\Delta_{1}, \dots, \Delta_{n}\}$ at stage {\sf s}, i.e.\ where each of $\bigvee\Delta_{1}, \dots, \bigvee\Delta_{n}$ is derived according to {\sf MinDab}.
%\end{definition}
%%
%Choice sets provide selections of abnormalities that might turn out to be true at a stage {\sf s}. The choice set of an empty set of minimal disjunction of abnormalities is empty. Now we translate the condition into a new marking rule:
%%, where again $\Sigma=\bigcup\{\Gamma, \Omega^{-}\}$:  
%
%
%%\begin{definition}[Marking for Minimal Abnormality]
%%$\TurnMarked{\Gamma; \Omega^{-}}{B}$ iff for any $\Sigma \in \Phi_{{\sf s}}(\Gamma)$, $\Sigma\cap \Omega^{-}\neq \emptyset$ and for some $\Sigma \in \Phi_{{\sf s}}(\Gamma)$ there is no ${\sf s}$ such that  $\Turn{\Gamma;\Omega^{-}}{B}$ and $\Sigma\cap \Omega^{-}\neq \emptyset$.
%%\end{definition}
%
%
%\begin{mathpar}
%\infer*[right=$\XBox$MA]{
%\Turn{\Gamma;\cdot}{\Delta^{min}_{i\dots n}}\\
%\TurnNext{\Gamma;\Psi^{-}}{\psi}\\
%{\Psi\cap \phi, \forall\phi \in\Phi_{\sf s}(\Gamma)\neq \emptyset}}  
%{\TurnMarkedNextNextMA{\Gamma;\cdot}{\psi}}
%\end{mathpar}
%
%
%\begin{mathpar}
%\infer*[right=$\XBox$MA2]{
%\Turn{\Gamma;\cdot}{\Delta^{min}_{i\dots n}}\\
%\TurnNext{\Gamma;\Psi^{-}}{\psi}\\
%\TurnNext{\Gamma;\Xi^{-}}{\psi}\\
%{\Xi,\Psi\cap \phi \in\Phi_{\sf s}(\Gamma)\neq \emptyset}}  
%{\TurnMarkedNextNextMA{\Gamma;\cdot}{\psi}}
%\end{mathpar}
%
%
%%
%This rule tells us that an {\sf Adaptive ND}-formula at stage {\sf s} is \textit{not} marked when: either $\Phi_{\sf s}(\Gamma)=\emptyset$; or $\exists\Xi\in\Phi_{\sf s}(\Gamma)$ such that $\Xi\cap\Omega^{-}=\emptyset$ possibly according to some ordering criterion;  and $\forall \Xi\in\Phi_{\sf s}(\Gamma)$, the formula at hand is derived under some condition that does not intersect with any of the minimal choice sets. In other words, in case $\Delta_{i}$ on the left-hand side of $\vdash$ at some stage {\sf s} has a non-empty-intersection with some $\Xi\in\Phi_{\sf s}(\Gamma)$, then the interpretation of $\Xi$ falsifies the formula derived at {\sf s}. This marking rule is further specified by establishing that not every $\Xi\in\Phi_{\sf s}(\Gamma)$ is treated in the same way. Hence, choice sets can be ordered according to some criterion (lexicographic, by counting, and so on) and relative to an inclusion relation that orders derivable formulas in view of the abnormality degree of their conditions. The most simple such ordering is done in function of the \textit{number} of abnormalities that are held as conditions of a given formula: the less the cardinality of such a set, the less abnormal the model (and hence, the more preferred the derivation). 
%
%Consider the above example again and the construction of minimal choice sets:
%
%$$
%\begin{array}{l}
%\Phi_{\sf 2}(\Gamma):=\{B\wedge \neg B\}\\
%\Phi_{\sf 6}(\Gamma):=\{\neg B\wedge \neg\neg B\}\\
%\Phi_{\sf 6}(\Gamma):=\{\{B\wedge \neg B\},\{\neg B\wedge \neg\neg B\}\}\\
%\end{array}
%$$
%%
%By this ordering one would consider abnormalities at stage $2$ less serious than those at stage $6$. But notice how this result will be obtained stage by stage. Hence the previous derivation would proceed in view of: first falsifying formulas obtained under condition $\Phi_{\sf 2}(\Gamma)$; then once $\Phi_{\sf 6}(\Gamma):=\{\neg B\wedge \neg\neg B\}$ is obtained, by re-enabling the former and marking the latter )where $\Pi$ abbreviates the derivation as above:
%
%
%\begin{mathpar}
%\infer*[right=UR]
%{
%\infer*[right=$\XBox$MA]
%{
%\infer*[right=RC]{
%\infer*[right=$\vee_{CL}$] {
%\infer*[right=$\XBox$MA]{
%\infer*[right=RU]{\Pi} {\TurnFour {\Gamma; (\{B\wedge \neg B\}\in \Phi_{{\sf 2}}(\Gamma))^{-}}{\{B\wedge \neg B\}}}
%}
%{\TurnMarkedFiveMA{\Gamma; (\{B\wedge \neg B\})^{-}}{B}}
%}
%{\TurnSix {\Gamma;\cdot}{\{\neg B\wedge \neg\neg B\};{\{B\wedge \neg B\}}}}
%}
%{\TurnSeven {\Gamma; (\{\neg B\wedge \neg\neg B\}\in \Phi_{{\sf 6}}(\Gamma))^{-}}{\neg B}}}
%{\TurnMarkedEightMA{\Gamma; \cdot}{\neg B}}
%}
%{\TurnNine{\Gamma;(\{\neg B\wedge \neg\neg B\})^{-}}{B}}
%\end{mathpar}
%%
%%
%%\infer*[right=RU] {\infer*[right=$\Gamma\Omega^{-}$] {\infer*[right=PREM] {\phantom{xx}} {\TurnOne {\Gamma; \cdot}{B}}} {\TurnTwo {\Gamma; \{B\wedge \neg B\}^{-}}{B}}\\ \infer*[right=PREM] {\phantom{xx}} {\TurnThree {\Gamma; \cdot}{\neg B}}}
%
%In this case the formula $B$ derived at stage $2$ is first marked, when the only derived $\Delta$ is the one on whose condition $B$ is derived; later, it get unmarked because the condition on which it is derived is safe when one considers $\Delta_{6}=\{\neg B\wedge \neg\neg B\}$ and it can be further derived under such condition.

\subsection{An example with $\bigvee(\Delta^{min})$-selection}


The previous example is rather simple, in that it simply indicates a formula that is first derived under an adaptive condition (referring to an abnormal formula assumed to be false), and then retracted after that condition is validated again. 

Let us consider now a slightly more complex example. We want to show a situation in which a disjunction of two abnormalities can be derived: accordingly, there might be more than one formula to be marked. Let us start with a premise set $\Gamma=\{(p \vee r),\neg p,(p\vee q), \neg q, (\neg p \rightarrow q)\}$. Now consider the following derivation, dubbed $\mathbb{D}$:



\begin{mathpar}
\infer*[right=RC]{
\infer*[right=$\wedge$I] {
\infer*[right=$\vee$E]{ 
\infer*[right=PREM] {\phantom{xx}} {\TurnOne {\Gamma; \cdot}{(p \vee r)}}}{\TurnTwo {\Gamma;\cdot}{p, r}}\\ 
\infer*[right=PREM] {\phantom{xx}} {\TurnThree {\Gamma; \cdot}{\neg p}}}{\TurnFour {\Gamma; \cdot}{(p\wedge \neg p), r}}\\
{(p \wedge \neg p)\in \Omega}}{\TurnFive {\Gamma;(p \wedge \neg p)^{-}}{r}}
\end{mathpar}
\bigskip

At stage {\sf 4} a disjunction of an abnormality with $r$ is derived, and by {\sf RC} at stage {\sf 6} the formula $r$ is derived alone, assuming the relevant abnormality false. Let us now consider the following derivation, dubbed $\mathbb{D}^{'}$:

\begin{mathpar}
\infer*[right=RC]{
\infer*[right=$\wedge$I] {
\infer*[right=$\vee$E]{ 
\infer*[right=PREM] {\phantom{xx}} {\TurnSix {\Gamma; \cdot}{(p \vee q)}}}{\TurnSeven {\Gamma;\cdot}{p, q}}\\ 
\infer*[right=PREM] {\phantom{xx}} {\TurnEight {\Gamma; \cdot}{\neg p}}}{\TurnNine {\Gamma; \cdot}{(p\wedge \neg p), r}}\\
\infer*[]{\phantom{xxxx}}{\TurnTen{\Gamma; \cdot}{\neg q}}}{\TurnEleven {\Gamma;\cdot}{(p \wedge \neg p), (q\wedge \neg q)}}
\end{mathpar}
\bigskip

Here the previously derived abnormality $(p \wedge \neg p)$ is derived in disjunctive form with a new abnormality $(q \wedge \neg q)$ at stage {\sf 11}, where the latter is obtained by $\wedge$I from stages {\sf 7,9}. If we join now the two branches $\mathbb{D,D^{\prime}}$ to form $\mathbb{E}$, we are allowed a marking step:

\begin{mathpar}
\infer*[right=\XBox]{
{\infer*[]{\mathbb{D}}{\TurnFive {\Gamma;(p \wedge \neg p)^{-}}{r}}}\\{\infer*[]{\mathbb{D^{\prime}}}{\TurnEleven {\Gamma;\cdot}{(p \wedge \neg p), (q\wedge \neg q)}}}\\{(p \wedge \neg p)\in \Delta^{min}}
}{\TurnMarkedTwelveREL{\Gamma; \cdot}{r}}
\end{mathpar}
\bigskip

At stage {\sf 12} the formula $r$ is no longer valid, because its adaptive condition is a minimal abnormal formula of a derived disjunction of abnormalities. Now we can provide a further extension of this derivation dubbed $\mathbb{D^{\prime\prime}}$:

\begin{mathpar}
\infer*[right=$\wedge$ I]{
\infer*[right=$\rightarrow$ I]{
\infer*[right=PREM]{\phantom{xxx}}{\TurnThirteen{\Gamma;\cdot}{\neg p}}\\ \infer*[right=PREM]{\phantom{xxx}}{\TurnFourteen{\Gamma;\cdot}{\neg p\rightarrow q}}}
{\TurnFifteen{\Gamma; \cdot}{q}}\\{
\infer*[right=PREM]{\phantom{xx}}{\TurnSixteen{\Gamma;\cdot}{\neg q}}}}{\TurnSeventeen {\Gamma; \cdot}{q \wedge \neg q}}

\end{mathpar}
\bigskip

$\mathbb{D^{\prime\prime}}$ has the effect of producing a new minimal abnormality at stage {\sf 17}. This also means that if we derive a copy of derivation $\mathbb{D}$, where each step is re-numbered consecutively, and join it to $\mathbb{D^{\prime\prime}}$ and $\mathbb{E}$, it is possible to establish again $(p \wedge \neg p)$ as an adaptive condition and accoridngly derive again the judgement that was marked at stage $12$, as follows:


\begin{mathpar}
\infer*[right=RC*]{
\infer*[]{\mathbb{E}}{\TurnMarkedTwelveREL{\Gamma; \cdot}{r}}\\
\infer*[]{\mathbb{D^{\prime\prime}}}{\TurnSeventeen {\Gamma; \cdot}{q \wedge \neg q}}\\
\infer*[]{\mathbb{D}}{\TurnEighteen {\Gamma;\cdot}{(p\wedge \neg p), r}}
%\\{(p\wedge \neg p)\in \Omega}
}
{\TurnNineteen {\Gamma;(p \wedge \neg p)^{-}}{r}}

\end{mathpar}
\bigskip

where $*$ is the side condition that $(p\wedge \neg p)\in \Omega$. If the derivation is no longer extended, the formula $r$ can be considered finally derived. In the next section we complete our system with the required meta-theoretical analysis needed to define derivability at stage and final derivability.

\section{Derivability}\label{sec:meta}

In the example from the previous section we have illustrated how the marking condition establishes a dynamic derivability relation, which allows to derive formulas and retract them. Whenever a certain formula is derived on some $\phi\in \Delta^{min}$ adaptive condition, it might still be marked afterwards according to $\XBox R$.
% or $\XBox MA$. 
This gives us a notion of derivability at stage: 

\begin{definition}[Derivability at stage]
%$\Turn{\Gamma; \phi^{-}}{\psi}$ iff at ${\sf s}$ it is not the case that $\TurnMarked{\Gamma}{\psi}$.
A formula $\psi$ is derived at stage {\sf s}  iff it is not the case that $\TurnMarked{\Gamma; \cdot}{\psi}$.
%$\Turn{\Gamma; \cdot}{\phi,\psi}$
\end{definition}

A more stable notion of derivability holds when marking is no longer possible.
% Because our left-hand side of the $\vdash$ sign, hence our ``premise set'', includes the $\vee_{\sf CL}$ connective for $Dab$-formulas, it is in principle possible to generate trees where some standard adaptive consequences (i.e. consequences of a corresponding AL in standard format) would be first marked and then never get unmarked.\footnote{These results are based on the generic format for Adaptive logics presented in \cite{strasservandeputte12}. A different approach that allows insertion of lines in proof trees is given for the Standard Format in \cite{batens2009}.}
%
%[HERE AN EXAMPLE]
%
%To get around this problem and provide a stable notion of derivability
To this aim, one requires that the stage {\sf s} at which a formula $\phi$ is derived remains unmarked in all the extensions of the derivation tree which can be obtained by using all \textit{relevant} abnormalities as adaptive conditions. This relevance criterion is essential if one wants to guarantee finiteness  of the proof tree to be surveyed in order to establish whetehr a formula is never marked (again), We define therefore a set of \textit{abnormalities relevant to $\Gamma$}. to do so we first identify the union set of all subformulas of the premise set $\Gamma$:


%\begin{definition}
%$Sf(\phi)=\{\psi \mid \psi$ is a subformula of $ \phi\}$
%\end{definition}


\begin{definition}[Subformulas of the premise set]
$Sf(\Gamma)=\bigcup_{\phi \in \Gamma} \{\psi \mid \psi$ is a subformula of $ \phi\}$
\end{definition}


From $Sf(\Gamma)$ we the construe all the possible abnormalities which can be obtained by its members:

\begin{definition}[Abnormalities relevant to the premise set]
$\Omega(\Gamma)=\{\psi\wedge \neg \psi \mid \psi\in Sf(\Gamma)\}$
\end{definition}

%\begin{definition}
%Let $P$ be a proof-tree of {\sf AdaptiveND}. We call $P^{\sf ext}$ the complete extension of $P$ at stage {\sf s} if $P^{\sf ext}$ extends $P$ by a possibly infinite number of derivation steps such that 
%
%\begin{enumerate}
%\item if $\Turn{\Gamma;\cdot}{Dab(\Delta)}$, then for all derivable $\Delta^{'}\subseteq\Delta$, it holds $\TurnPrime{\Gamma;\cdot}{Dab(\Delta^{'})}$, for some $s'<s$;
%\item if $\Turn{\Gamma;\Delta^{-}}{\phi}$, then $\Turn{\Gamma;\Delta'^{-}}{\phi}$
%\end{enumerate}
%\end{definition}
%

Given this preparatory work, we now introduce the notion of a \textit{complete proof-tree} with respect to derivable relevant disjunction of abnormalities:

\begin{definition}[Completeness relative to relevant abnormalities ]
Let $P$ be a proof-tree of {\sf AdaptiveND}. We say that $P$ is complete relative to $\Omega(\Gamma)$ at stage {\sf s} if  $\TurnPrime{\Gamma;\cdot}{\bigvee(\Delta)}$, for every derivable $\bigvee(\Delta)$ with $\Delta\subseteq\Omega(\Gamma)$ and some {\sf s'}$<${\sf s}.

%
%\begin{enumerate}
%\item  it holds $\TurnPrime{\Gamma;\cdot}{Dab(\Delta^{'})}$, for some $s'<s$;
%\item there is a $\psi$ such that $\TurnPrimePrime{\Gamma;\Delta'^{-}}{\psi}$, for some $s<s''<s$.
%\end{enumerate}
\end{definition}


%By the first requirement all possible $Dab(\Delta)^{min}_{s}$ have been derived for  {\sf s}; and by the second requirement every formula is derived under the minimal conditions (hence any relevant condition for the marking has been obtained already).

We can now formulate our notion of final derivability:

\begin{definition}[Final Derivability]
A formula $\psi$ is finally derived $\TurnChecked{\Gamma;\phi^{-}}{\psi}$ iff there is a stage {\sf s}  in some complete proof-tree $P$
 such that $\Turn{\Gamma;\phi^{-}}{\psi}$ and $\phi \notin \Delta^{min}$.
%, where $\Delta$ is the conclusion obtained  at some stage of $P$ by an instance of the \textsc{MinDab} rule. 
\end{definition}
%
The definition guarantees final derivability for any derived formula whose  adaptive condition is not minimal. Notice that the second requirement might not be satisfied at any finite stage {\sf s}, hence it might be guaranteed only at meta-theoretical level.


%\begin{definition}
%$\TurnADND{\Gamma}{\phi}$ iff $\TurnChecked{\Gamma;\Omega^{-}}{\phi}$
%\end{definition}
%
%Notice that not every finally derivable formula of {\sf AdaptiveND} is derivable at stage. In particular, for the case of {\sf AdaptiveND}, where the disjunction used to construct $Dab$-formulas is explicitly admitted in the premise set by the extension of a given $\Gamma$ with $Dab(\Delta)^{-}$ on the left-hand side of $\vdash$, one can conceive of cases in which a finally derivable $\phi$ is not derivable at any finite stage of a proof-tree.\footnote{For an example see Strasser PHD, ch.2.8.} 

%\section{Structural Rules}
%
%
%\begin{theorem}[Restricted Weakening]
%{\sf AdaptiveND} satisfies Weakening:
%
%\begin{enumerate}
%\item If $\Turn{\Gamma;\cdot}{\phi_{1}}$, then $\Turn{\Gamma, \phi_{2};\cdot}{\phi_{1}}$, with $\phi_{2}$ fresh.
%\item If $\Turn{\Gamma; \Omega^{-}}{\phi_{1}}$, then $\Turn{\Gamma, \phi_{2}; \Omega^{-}}{\phi_{1}}$, with $\phi_{2}$ fresh, and there is no $\phi_{3}\in\Gamma$ such that $\phi_{2},\phi_{3}\in Dab(\Delta)$.
%\item If $\Turn{\Gamma;\Omega^{-}}{\phi}$, then $\Turn{\Gamma;\Omega^{-},\Delta_{i}}{\phi}$, iff $\Delta_{i}\supseteq\Delta_{j}$, for every $\Delta_{j}\in \Omega$.
%\end{enumerate}
%\end{theorem}
%
%\begin{proof}
%The first and second item are justified simply by $\Gamma$-formation rule with the appropriate restrictions on, respectively, freshness of the formula and $Dab$-formation by $\vee_{\sf CL}$-rule. The third item works as weakening on $\Omega^{-}$ by $\Gamma\Omega^{-}$-formation rule, with the appropriate restriction on minimal $Dab$-formulas in the already present set of abnormal premises.
%\end{proof}
%
%
%\begin{theorem}[Contraction]
%{\sf AdaptiveND} satisfies Contraction:
%
%\begin{enumerate}
%\item If $\Turn{\Gamma, \phi_{1}, \phi_{1};\cdot}{\phi_{2}}$, then $\Turn{\Gamma, \phi_{1};\cdot}{\phi_{2}}$.
%\item If $\Turn{\Gamma, \phi_{1}, \phi_{1}; \Omega^{-}}{\phi_{2}}$, then $\Turn{\Gamma, \phi_{1};\Omega^{-}}{\phi_{2}}$.
%\item If $\Turn{\Gamma;\Omega^{-}, \Delta_{i}, \Delta_{i}}{\phi}$, and $\Delta_{i}\supseteq\Delta_{j}$, for every $\Delta_{j}\in \Omega$,  then $\Turn{\Gamma;\Omega^{-},\Delta_{i}}{\phi}$.
%\end{enumerate}
%\end{theorem}
%
%\begin{proof}
%First and second item by induction on formulas (where $\Omega^{-}$ being empty is irrelevant). For the third item, it is essential that the sets of abnormal formulas involved in the contraction operation be irrelevant with respect to minimal $Dab$-formulas formation
%\end{proof}
%
%
%
%\begin{theorem}[Exchange]
%{\sf AdaptiveND} satisfies exchange up to context well-formedness:
%
%\begin{enumerate}
%\item If $\Turn{\Gamma, \phi_{1}, \phi_{2}; \cdot}{\phi_{3}}$, then $\Turn{\Gamma, \phi_{2}, \phi_{1};\cdot}{\phi_{3}}$.
%\item If $\Turn{\Gamma, \phi_{1}, \phi_{2}; \Omega^{-}}{\phi_{3}}$, then $\Turn{\Gamma, \phi_{2}, \phi_{1};\Omega^{-}}{\phi_{3}}$.
%\item If $\Turn{\Gamma; \Omega^{-}, \Delta_{i}, \Delta_{j}}{\phi}$, and $\Delta_{i}, \Delta_{j}\supseteq\Delta_{k}$, for every $\Delta_{k}\in \Omega$,  then\\ $\Turn{\Gamma; \Omega^{-},\Delta_{j}, \Delta_{i}}{B}$.
%\end{enumerate}
%\end{theorem}
%
%\begin{proof}
%First and second item by induction on formulas (where $\Omega^{-}$ being empty is irrelevant). For the third item, it is again essential that the sets of abnormal formulas involved in the exchange operation be irrelevant with respect to minimal $Dab$-formulas formation.
%\end{proof}

\bibliographystyle{plain}
\bibliography{primiero}

\end{document}
